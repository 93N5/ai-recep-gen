# ai-recep-gen

## set it up
**local llm**

start a local server. lmstudio or ollama;

set your desired apiUrl and you should be done.